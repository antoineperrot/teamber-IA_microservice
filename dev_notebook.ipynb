{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc804521",
   "metadata": {},
   "source": [
    "## en-tête des requêtes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7205858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "api_url = 'https://development.api.wandeed.com/api/lst/search?offset=0&limit=500'\n",
    "access_token='Bearer eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJydXRUeHJ5dlltOUVZcGhpRjRxak45ajFvTktLNnU4YUhuM1QySFFSUU5FIn0.eyJleHAiOjE2NjMwNzExMzMsImlhdCI6MTY2MzA1MzEzMywiYXV0aF90aW1lIjoxNjYzMDUzMTMyLCJqdGkiOiJiYmViZDY1ZC00ODgwLTQ3MDUtOTdiOS1kNWNjYjFjOWFjZjIiLCJpc3MiOiJodHRwczovL2RldmVsb3BtZW50LmF1dGgud2FuZGVlZC5jb20vYXV0aC9yZWFsbXMvd2FuZGVlZC1yZWFsbSIsImF1ZCI6ImFjY291bnQiLCJzdWIiOiIzMWZmODY3NC1iOGZhLTQyMmYtYWM3NC02YzFjZGI2YTUwZGUiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJ3YW5kZWVkLWNsaWVudCIsIm5vbmNlIjoiMDY1MjU1NmMtMjA2Ny00ZTA3LTg2N2ItZTU3YTc4ZGFmNGQxIiwic2Vzc2lvbl9zdGF0ZSI6IjJlNTNhMDJmLWQ0YTQtNDU5OS05YjRhLWI0YjZmMDM2MTY0YyIsImFjciI6IjEiLCJhbGxvd2VkLW9yaWdpbnMiOlsiaHR0cHM6Ly8qLndhbmRlZWQuY29tLyoiLCJodHRwczovLyouYXBpLndhbmRlZWQuY29tLyoiLCIqIiwiaHR0cHM6Ly8qLmFkbWluLndhbmRlZWQuY29tLyoiLCJodHRwczovLyouYXV0aC53YW5kZWVkLmNvbSJdLCJyZWFsbV9hY2Nlc3MiOnsicm9sZXMiOlsiZGVmYXVsdC1yb2xlcy13YW5kZWVkLXJlYWxtIiwib2ZmbGluZV9hY2Nlc3MiLCJ1bWFfYXV0aG9yaXphdGlvbiJdfSwicmVzb3VyY2VfYWNjZXNzIjp7ImFjY291bnQiOnsicm9sZXMiOlsibWFuYWdlLWFjY291bnQiLCJtYW5hZ2UtYWNjb3VudC1saW5rcyIsInZpZXctcHJvZmlsZSJdfX0sInNjb3BlIjoib3BlbmlkIGVtYWlsIHByb2ZpbGUiLCJzaWQiOiIyZTUzYTAyZi1kNGE0LTQ1OTktOWI0YS1iNGI2ZjAzNjE2NGMiLCJ1dGxfc3BrdXRpbGlzYXRldXIiOjEsInV0bF91dGlsaXNhdGV1cl9yb2xlcyI6IlsxXSIsInV0bF9jcHJlbm9tIjoiR2F5bG9yZCIsImVtYWlsX3ZlcmlmaWVkIjp0cnVlLCJ1dGxfc2FwcGFydGVuYW5jZSI6WzIsMzhdLCJ1dGxfY25vbSI6IlBldGl0IiwicHJlZmVycmVkX3VzZXJuYW1lIjoiZ2F5bG9yZC5wZXRpdEB0ZWFtYmVyLmZyIiwibG9jYWxlIjoiZnIiLCJnaXZlbl9uYW1lIjoiR2F5bG9yZCIsInV0bF9zZmtpbnN0YW5jZSI6MSwidXRsX3NhZG1pbmlzdHJlciI6W10sIm5hbWUiOiJHYXlsb3JkIFBldGl0IiwidXRsX3Nkcm9pdHNhY2NlcyI6WzYwLDMsNCw1LDE1LDI1LDI2LDMzLDM0LDM1LDM2LDM3LDQwLDQxLDQ0LDQ1LDQ2LDQ3XSwiZmFtaWx5X25hbWUiOiJQZXRpdCIsImVtYWlsIjoiZ2F5bG9yZC5wZXRpdEB0ZWFtYmVyLmZyIiwidXNlcl9ncm91cHMiOlsyLDM4LDYwLDMsNCw1LDE1LDI1LDI2LDMzLDM0LDM1LDM2LDM3LDQwLDQxLDQ0LDQ1LDQ2LDQ3XX0.DGvq43C3ZqBNi7-ZUmrHXm5_iV7nC5gAo-d4cRhdYU8KjsB9N6i4IKxPFPnbalHJpZe9g4MGiZdWGbVYnBstuNcT5ioQOrlZP1BWUmN8Nkq-yYrnL3uHf7VB8mixOAu0b3kpF7r2XoytCvslDFBGaDcWGPJkIdMNFHw3fMKT-smjj1DTP01RuSUc-ItGHn3-CBBDkEocpwTTfBTEDEwcFZ1n69ct1XjYQPuNvKp2PCoje3Y68h6tGSllhOp6ikksx7-inXvMZ6u9ucoshrAkBvb2PLTkQ6cEZxdqz-ymJQsx4N3pxp71-S0xAsSFM8l9JlQ4Ittkmz1ReDkEKi0Vpw'\n",
    "\n",
    "headers={'Authorization': f'{access_token}',\n",
    "             'Content-Type':'application/json'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c50bf499",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://127.0.0.1:8000/get_data_task_assigner'\n",
    "res = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33869c0",
   "metadata": {},
   "source": [
    "### dict PROJET -> Liste Utilisateurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c616391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCES'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.json()['STATUT_RECUPERATION_DONNEES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "367fedc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antoi\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "# import librairies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## RECUPERATION DES DONNEES :\n",
    "# recuperation matrice_projet\n",
    "df_prj = pd.DataFrame(res.json()['matrice_projet']['data']['result'])\n",
    "# recuperation matrice_competence : on oublie les compétences pour lesquels les utl sont indéfinis\n",
    "df_cmp = pd.DataFrame(res.json()['matrice_competence']['data']['result']).dropna().reset_index(drop=True).astype(int)\n",
    "# recuperation des taches à assigner :\n",
    "df_tsk = pd.DataFrame(res.json()['taches']['data']['result'])\n",
    "# recuperation des disponibilites utl :\n",
    "df_dsp = pd.DataFrame(res.json()['dispos_utilisateurs']['data']['result'])\n",
    "\n",
    "\n",
    "\n",
    "## CONVERSION DES IDS Wandeed en Identifiant local pour certaines variables\n",
    "# sauvegarde des id utilisateurs ET conservation des ids_utl uniques\n",
    "lst_utl = []\n",
    "lst_utl.append(list(np.unique(df_prj['utl_spkutilisateur'])))\n",
    "lst_utl.append(list(np.unique(df_cmp['emc_sfkutilisateur'])))\n",
    "id_utl = list(np.sort(np.unique(np.sum(lst_utl,dtype=object))))\n",
    "\n",
    "# id_utl vers entier (local) ET entier (local) vers id_utl\n",
    "utl_to_int = {_id : _int for _int,_id in enumerate(id_utl)}\n",
    "int_to_utl = {_int: _id  for _int,_id in enumerate(id_utl)}\n",
    "\n",
    "# sauvegarde des id projets ET conservation des ids_prj uniques\n",
    "lst_prj = []\n",
    "lst_prj.append(list(np.unique(df_prj['int_sfkprojet'])))\n",
    "lst_prj.append(list(np.unique(df_tsk['evt_sfkprojet'])))\n",
    "id_prj = list(np.sort(np.unique(np.sum(lst_prj,dtype=object))))\n",
    "\n",
    "# id_prj vers entier (local) ET entier (local) vers id_prj\n",
    "prj_to_int = {int(_id) : int(_int) for _int,_id in enumerate(id_prj)}\n",
    "int_to_prj = {int(_int): int(_id)  for _int,_id in enumerate(id_prj)}\n",
    "\n",
    "# sauvegardes des ids competences ET conservation des ids_cmp uniques\n",
    "lst_cmp = []\n",
    "lst_cmp.append(list(np.unique(df_cmp['emc_sfkarticle'])))\n",
    "lst_cmp.append(list(np.unique(df_tsk['lgl_sfkligneparent'])))\n",
    "id_cmp = list(np.sort(np.unique(np.sum(lst_cmp,dtype=object))))\n",
    "\n",
    "# id_cmp vers entier (local) ET entier (local) vers id_cmp\n",
    "cmp_to_int = {int(_id) : _int for _int,_id in enumerate(id_cmp)}\n",
    "int_to_cmp = {int(_int): int(_id)  for _int,_id in enumerate(id_cmp)}\n",
    "\n",
    "# sauvegardes des ids tsk ET conservation des ids_tsk uniques\n",
    "lst_tsk = []\n",
    "id_tsk = list(np.sort(np.unique(df_tsk['evt_spkevenement'])))\n",
    "\n",
    "\n",
    "# id_tsk vers entier (local) ET entier (local) vers id_tsk\n",
    "tsk_to_int = {int(_id) : int(_int) for _int,_id in enumerate(id_tsk)}\n",
    "int_to_tsk = {int(_int): int(_id)  for _int,_id in enumerate(id_tsk)}\n",
    "\n",
    "# Comptage nombre cmp, utl, tsk, prj.\n",
    "n_cmp = len(id_cmp)\n",
    "n_prj = len(id_prj)\n",
    "n_tsk = len(id_tsk)\n",
    "n_utl = len(id_utl)\n",
    "\n",
    "# AJOUT DES VARIABLES LOCALES DANS LES DATAFRAMES\n",
    "\n",
    "df_cmp['cmp'] = df_cmp['emc_sfkarticle'].map(cmp_to_int)\n",
    "df_cmp['utl'] = df_cmp['emc_sfkutilisateur'].map(utl_to_int)\n",
    "df_tsk['tsk'] = df_tsk['evt_spkevenement'].map(tsk_to_int)\n",
    "df_tsk['cmp'] = df_tsk['lgl_sfkligneparent'].map(cmp_to_int)\n",
    "df_tsk['prj'] = df_tsk['evt_sfkprojet'].map(prj_to_int)\n",
    "df_prj['utl'] = df_prj['utl_spkutilisateur'].map(utl_to_int)\n",
    "df_prj['prj'] = df_prj['int_sfkprojet'].map(prj_to_int)\n",
    "df_dsp['utl'] = df_dsp['utl_spkutilisateur'].map(utl_to_int)\n",
    "\n",
    "# commodités pour plus tard\n",
    "df_cmp = df_cmp.sort_values(by='utl')\n",
    "\n",
    "## RESOLUTION PROBLEME : CONSTRUCTION DES ARCS DE CORRESPONDANCES TACHES <-> UTILISATEUR\n",
    "# construction d'un dictionnaire qui contient, pour chaque prjet, la liste des utilisateurs en faisant parti.\n",
    "d_prj_to_utl = df_prj.groupby('prj')['utl'].apply(np.sort).to_dict()\n",
    "# d_prj_to_utl\n",
    "\n",
    "# construction matrice de cmp np.array\n",
    "mat_cmp = np.zeros((n_cmp, n_utl)).astype(int)\n",
    "\n",
    "# REMPLISSAGE MATRICE DE COMPETENCE\n",
    "\n",
    "# ce dict est organisé en arborescence : utl//comp//niveau\n",
    "d_utl_to_cmp_to_lvl = {}\n",
    "utl_competants = list(np.unique(df_cmp['utl']))\n",
    "for utl in utl_competants:\n",
    "    d_utl_to_cmp_to_lvl[utl] = {}\n",
    "    df_cmp_tmp = df_cmp.loc[df_cmp['utl']==utl,]\n",
    "    for i, row in df_cmp_tmp.iterrows():\n",
    "        cmp = row['cmp'] ; lvl = row['emc_sniveau'];\n",
    "        d_utl_to_cmp_to_lvl[utl][cmp] = lvl\n",
    "        \n",
    "for utl in d_utl_to_cmp_to_lvl:\n",
    "    for cmp in d_utl_to_cmp_to_lvl[utl].keys():\n",
    "        lvl = d_utl_to_cmp_to_lvl[utl][cmp]\n",
    "        mat_cmp[cmp, utl] = lvl\n",
    "        \n",
    "# REMPLISSAGE MATRICE PROJET :\n",
    "mat_prj = np.zeros((n_prj, n_utl)).astype(int)\n",
    "for prj in range(n_prj): \n",
    "    for utl in d_prj_to_utl[prj]:\n",
    "        mat_prj[prj, utl] = 1\n",
    "\n",
    "        \n",
    "# # dictionnaire mapping utl -> dispo        \n",
    "# d_utl_to_dsp = {int(row['utl']):row['utl_sdispo'] for _, row in df_dsp.iterrows()}          \n",
    "\n",
    "# MOCKING pour les dsp utl#########################################################\n",
    "d_utl_to_dsp = {utl:np.random.randint(15,50)*0.1 for utl in range(n_utl)}\n",
    "d_utl_to_dsp['not assigned'] = np.sum(list(d_utl_to_dsp.values()))\n",
    "\n",
    "# DEFINITION DES ARCS\n",
    "d_tsk_to_cmp = {int(row['tsk']):int(row['cmp']) for i, row in df_tsk.iterrows()}\n",
    "d_tsk_to_prj = {int(row['tsk']):int(row['prj']) for i, row in df_tsk.iterrows()}\n",
    "d_tsk_to_lgt = {int(row['tsk']):row['evt_dduree'] for i, row in df_tsk.iterrows()}\n",
    "\n",
    "arcs = []\n",
    "n_arcs = 0\n",
    "cost_func = []\n",
    "for tsk in range(n_tsk):\n",
    "    for utl in range(n_utl):\n",
    "        cmp = d_tsk_to_cmp[tsk]\n",
    "        prj = d_tsk_to_prj[tsk]\n",
    "        lvl = mat_cmp[cmp, utl]\n",
    "        utl_on_prj = mat_prj[prj, utl]\n",
    "        if lvl >= 0 and utl_on_prj : \n",
    "            arcs.append( tuple((tsk,utl)) )\n",
    "            cost_func.append(lvl)\n",
    "n_arcs = len(arcs)\n",
    "\n",
    "# chaque tache a également la possibilité de ne pas être assignée, ce qui est fortement pénalisé\n",
    "penalty = -100\n",
    "for tsk in range(n_tsk):\n",
    "    arcs.append(tuple((tsk,'not assigned')))\n",
    "    cost_func.append(penalty)\n",
    "    \n",
    "    \n",
    "# ajout des variables d'écart (slack variables)\n",
    "cost_func += [0]*n_utl  \n",
    "cost_func = np.array(cost_func)\n",
    "\n",
    "# FABRICATION DES MATRICES A et B POUR RESOUDRE AX<=B\n",
    "\n",
    "#equality constraints :\n",
    "lst_lgt = [d_tsk_to_lgt[tsk] for tsk in range(tsk)]\n",
    "A = np.zeros((n_tsk + n_utl , n_arcs + n_tsk + n_utl ))\n",
    "b = np.zeros(n_tsk + n_utl)\n",
    "\n",
    "# contrainte d'égalité : distribution de toutes les heures\n",
    "for tsk in range(n_tsk):\n",
    "    for idx_arc, arc in enumerate(arcs):\n",
    "        if arc[0] == tsk:  A[tsk, idx_arc] = 1\n",
    "    b[tsk] = d_tsk_to_lgt[tsk]\n",
    "            \n",
    "# contraintes d'inégalités : respect des disponibilités de travail\n",
    "for utl in range(n_utl):\n",
    "    for idx_arc, arc in enumerate(arcs):\n",
    "        utl_2 = arc[1]\n",
    "        if utl_2 == utl : A[n_tsk + utl, idx_arc] = 1\n",
    "    A[n_tsk + utl, n_arcs + n_tsk + utl] =   1 # variable d'écart (slack variable)\n",
    "    b[n_tsk + utl] = d_utl_to_dsp[utl]\n",
    "\n",
    "    \n",
    "## RESOLUTION DU PROBLEME DE PROGRAMMATION LINEAIRE\n",
    "from scipy.optimize import linprog\n",
    "l = linprog(-cost_func,A_eq=A,b_eq=b,method=\"simplex\",options={'maxiter':1500})\n",
    "if l.status !=0 :\n",
    "    l = linprog(-c, A_eq=A,b_eq=b,method='interior-point',options={'maxiter':1500})\n",
    "    if l.status != 0:\n",
    "        outcome = 'The system has no solution'\n",
    "    else :\n",
    "        outcome = 'success'\n",
    "else :\n",
    "    outcome = 'success'\n",
    "\n",
    "solution = l.x\n",
    "\n",
    "## MISE EN FORME DE LA SOLUTION\n",
    "def make_output_dataframe(solution, arcs):\n",
    "    out = pd.DataFrame()\n",
    "    for j in range(len(arcs)):\n",
    "        if solution[j] > 0 :\n",
    "            tsk, utl = arcs[j]\n",
    "            lvl = cost_func[j]\n",
    "            out = out.append(pd.DataFrame({\n",
    "                'tsk':[tsk],'utl':[utl],\n",
    "                'duree_assignee':[solution[j]],\n",
    "                'tsk_lgt':[d_tsk_to_lgt[tsk]],\n",
    "                'cmp':[d_tsk_to_cmp[tsk]],\n",
    "                'lvl':[lvl],\n",
    "                'dsp_utl':[d_utl_to_dsp[utl]],\n",
    "                'prj':[d_tsk_to_prj[tsk]]\n",
    "            } ))\n",
    "    out.reset_index(drop=True,inplace=True)  \n",
    "    out['duree_non_assignee'] = np.round(out['tsk_lgt'] - out['duree_assignee'],2)\n",
    "    out.loc[out['utl']=='not assigned','lvl'] = np.nan\n",
    "    return out\n",
    "\n",
    "df_out = make_output_dataframe(solution, arcs)\n",
    "\n",
    "## PRODUCTION DE STATISTIQUES D'INTERPRETATION DU RESULTAT\n",
    "\n",
    "# Statistiques par cmp\n",
    "avg_lvl = df_out.loc[df_out['utl']!='not assigned'].groupby('cmp')['lvl'].mean().rename('niveau_cmp_moyen_par_h_realisee')\n",
    "cmp_miss = df_out.loc[df_out['utl']=='not assigned'].groupby('cmp')['duree_assignee'].sum().rename('total_h_non_assignee')\n",
    "stat_cmp = pd.DataFrame([avg_lvl, cmp_miss]).T\n",
    "stat_cmp['total_h_non_assignee'] = stat_cmp['total_h_non_assignee'].fillna(0)\n",
    "stat_cmp.reset_index(inplace=True)\n",
    "\n",
    "# Statistiques par utl\n",
    "avg_lvl = df_out.drop(['tsk','tsk_lgt','cmp'],axis=1).loc[df_out['utl']!='not assigned']\n",
    "avg_lvl['niveau_moyen_execution_tsk'] = avg_lvl['duree_assignee']*avg_lvl['lvl']\n",
    "avg_lvl_exe_tsk = avg_lvl.groupby('utl')['niveau_moyen_execution_tsk'].mean()\n",
    "tot_h = df_out.groupby('utl')['duree_assignee'].sum().rename('total_h_assignees')\n",
    "stat_utl = pd.DataFrame([avg_lvl_exe_tsk, tot_h]).T\n",
    "stat_utl['tot_dsp'] = stat_utl.index.map(d_utl_to_dsp)\n",
    "stat_utl['taux_occupation'] = np.round(stat_utl['total_h_assignees'] / stat_utl['tot_dsp'], 2)\n",
    "stat_utl.reset_index(inplace=True)\n",
    "\n",
    "# Statistiques par tsk\n",
    "n_utl_per_tsk = df_out.loc[df_out['utl']!='not assigned'].groupby('tsk')['utl'].count().rename('n_utl_per_tsk').astype(int)\n",
    "pct_per_tsk = ((df_out.loc[df_out['utl']!='not assigned'].groupby('tsk')['duree_assignee'].sum()/pd.Series(d_tsk_to_lgt).sort_index()).fillna(0).rename('pct_assignation_tache')*100).astype(int)\n",
    "stat_tsk = pd.DataFrame([n_utl_per_tsk, pct_per_tsk]).T\n",
    "stat_tsk['n_utl_per_tsk'] =  stat_tsk['n_utl_per_tsk'].fillna(0).astype(int)\n",
    "stat_tsk['pct_assignation_tache'] =  stat_tsk['pct_assignation_tache'].astype(int)\n",
    "stat_tsk.reset_index(inplace=True)\n",
    "stat_tsk\n",
    "\n",
    "# Statistiques par prj\n",
    "unassigned_time_per_prj = df_out.groupby('prj')['duree_non_assignee'].sum().rename('temps_total_non_assigne')\n",
    "n_missing_cmp_per_prj = df_out.loc[df_out['utl']=='not assigned'].groupby('prj')['cmp'].count().rename('n_missing_cmp_per_prj')\n",
    "stat_prj = pd.DataFrame([unassigned_time_per_prj, n_missing_cmp_per_prj]).T\n",
    "stat_prj.reset_index(inplace=True)\n",
    "stat_prj['n_missing_cmp_per_prj'] =  stat_prj['n_missing_cmp_per_prj'].fillna(0).astype(int)\n",
    "stat_prj\n",
    "\n",
    "\n",
    "OUT = {'solution':df_out.to_dict(),\n",
    "      'statistics_for':{\n",
    "          'cmp':stat_cmp.to_dict(),\n",
    "          'utl':stat_utl.to_dict(),\n",
    "          'tsk':stat_tsk.to_dict(),\n",
    "          'prj':stat_prj.to_dict()\n",
    "      }}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
